- 数据如何存储的？
	- bustub 中最小的存储单元是 page，page 将实际存储在内存中的数据进行了的包装，还存放了一些 buffer pool 的标记信息，如固定计数、脏位、page ID 等等
	- 每个 page 的大小是 4096
- Buffer Pool 是什么
	- 是一个缓冲池，因为磁盘和内存读写效率不同，为了平衡两者之间的差距，实现了一个中间层缓冲池
	- 缓冲池是从磁盘读取的页面的内存缓存。 它本质上是在数据库内部分配的一个大内存区域，用于存储从磁盘获取的页面。
	- 缓冲池的内存区域组织为固定大小页面的数组。 每个数组条目称为一个帧。 当 DBMS 请求页面时，会将精确副本放入缓冲池的其中一个帧中。 然后，数据库系统可以在请求页面时首先搜索缓冲池。 如果找不到该页面，则系统会从磁盘中获取该页面的副本。 脏页被缓冲并且不会立即写回。 有关缓冲池的内存组织图，请参见图 2。
	- ![](pics/Pasted%20image%2020230502111352.png)
- Buffer Pool 有什么作用？如何实现的
- LRU-K 算法是什么，和 LRU 对比，为什么使用 LRU-K 算法？
	- LRU-K 算法是一种基于 LRU（Least Recently Used，最近最少使用）算法的变种，它将 LRU 算法中只考虑最近一次访问时间的思想扩展到了最近 K 次访问时间。在 LRU-K 算法中，每个页面都有一个访问计数器，记录了该页面最近 K 次访问的时间戳。当需要淘汰一个页面时，LRU-K 算法会选择访问计数器值最小的页面进行淘汰。
	- LRU-K 算法相比于 LRU 算法，能够更好地适应一些特殊场景，如存在周期性访问的页面或者存在热点数据的情况。但是，LRU-K 算法需要额外的计算和存储开销，同时 K 值的选择也需要根据具体场景进行调整。
- LRU 算法：
	- 最近最少使用的替换策略维护每个页面上次访问时间的时间戳。 DBMS 选择驱逐具有最旧时间戳的页面。 该时间戳可以存储在单独的数据结构中，例如队列，以允许排序并通过减少驱逐时的排序时间来提高效率。
- 为什么要用 LRU-K 算法：
	- 也就是说，LRU 和 CLOCK 容易受到顺序泛洪的影响，其中缓冲池的内容由于顺序扫描而被破坏。 由于顺序扫描会读取每一页，因此读取页面的时间戳可能无法反映我们实际需要的页面。 换句话说，最近使用的页面实际上是最不需要的页面
	- 一种解决方案是 LRU-K，它跟踪最后 K 个引用的历史作为时间戳，并计算后续访问之间的间隔。 此历史记录用于预测下一次访问页面的时间。
	- **对于数据库而言，某种程度上是可以预测要访问的页面的，比如最简单的自然连接两个表，用二重循环遍历每个块，对于循环内部的表来说，采用的是顺序扫描，这个时候最近一次访问的页面实际上是下一个循环最后才访问的页面，也就是最不需要的页面，如果用 LRU-K 算法的话，没有到达 k 次访问的话，会利用 FIFO 策略将最近访问的页面替换出去，对于经常访问的也就是到达 k 次访问的页面，会被认为比较活跃的缓冲块，替换会比较晚。**

---
- B+ 树概念，和 B 树对比，插入查找删除基本操作如何实现的，并发管理如何实现的，乐观锁和悲观锁对比？
	- B+Tree 是一种自平衡树数据结构，它保持数据排序并允许在 O(log(n)) 中进行搜索、顺序访问、插入和删除。 它针对读取/写入大块数据的面向磁盘的 DBMS 进行了优化
	- 几乎每个支持保序索引的现代 DBMS 都使用 B+ 树。 有一种特定的数据结构称为 B 树，但人们也使用该术语来泛指一类数据结构。 原始 B-Tree 和 B+Tree 之间的主要区别在于 B-Tree 在所有节点中存储键和值，而 B+ 树仅在叶节点中存储值。 现代 B+Tree 实现结合了其他 B-Tree 变体的特性，例如 Blink-Tree 中使用的兄弟指针
	- ![](pics/Pasted%20image%2020230502114005.png)
- B+ 树：B+Tree 是 M 路搜索树（其中 M 表示节点可以拥有的最大子节点数），具有以下属性：  
	• 它是完美平衡的（即，每个叶节点都处于相同的深度）。  
	• 除根以外的每个内部节点至少是半满的（M/2 − 1 <= 键数<= M − 1）。  
	• 每个有 k 个键的内部节点都有 k+1 个非空子节点。
- B+ 树插入操作：
	- 为了实现插入操作，首先需要找到对应的叶子节点 L
	- 找到叶子节点 L 之后，根据二分查找找到待插入的位置
		- 如果叶子节点 L 没有满，插入完成
		- 如果叶子节点 L 满了，将分裂成两个节点 L 和 L2，然后将 L2 的第一个节点作为 key 插入到父节点中
	- 父节点根据需要也进行分裂，依次类推
- B+ 树删除操作：
	- 和插入一样，首先找到待删除 key 对应的叶子节点 L
	- 然后删除叶子节点中对应的 key，删除之后
		- 如果叶子节点不满足 half full 状态，向兄弟节点考虑合并或重新分配
		- 合并，即兄弟节点和叶子节点键的数量加起来不足节点的最大值，两个节点合并成一个节点，然后在父节点中删除兄弟节点对应的 key，递归查看父节点是否需要合并或重新分配
		- 重新分配，将兄弟节点的第一个或最后一个移动到叶子节点中，同时修改父节点中对应的 key
- B+ 树并发控制：
	- B+ 树并发管理主要是 1）多个线程同时修改节点内容；2）一个线程正在遍历树，另外一个线程在拆分或合并节点；
	- **螃蟹规则**：是一种允许多个线程同时访问/修改 B+Tree 的方法， 基本思路如下：
		- 1. 父节点上锁；
		- 2. 为子节点上锁；
		- 3. 如果认为孩子“安全”，则为父节点解锁。 “安全”节点是指在更新时不会分裂、合并或重新分配的节点。
	- 搜索：从根节点往下，不断的对子节点加 **读锁**，然后释放父节点的的锁
	- 插入/删除：从根节点往下，对遍历的子节点加 **写锁**，然后判断这个子节点是否是安全的，如果是安全的，则立刻释放父节点往上所有祖先节点的锁。

---
notes-12
- DBMS 将 SQL 语句转换为查询计划。 查询计划中的运算符排列成树状。 数据从这棵树的叶子流向根。 树中根节点的输出就是查询的结果。 通常运算符是二进制的（1-2 个孩子）。 同一个查询计划可以以多种方式执行。
- **迭代器模型/火山模型** 通过为数据库中的每个运算符实现一个 Next 函数来工作。 查询计划中的每个节点在其子节点上调用 Next 直到到达叶节点，叶节点开始将元组发送到它们的父节点以进行处理。 然后在检索下一个元组之前尽可能地向上处理每个元组。 这在基于磁盘的系统中很有用，因为它允许我们在访问下一个元组或页面之前充分使用内存中的每个元组。 迭代器模型的示例图如图 1 所示。
- 迭代器模型中的查询计划运算符是高度可组合且易于推理的，因为每个运算符都可以独立于查询计划树中的父或子运算符来实现，只要它实现 Next 函数，如下所示：
	- 在每次调用 Next 时，如果没有更多的元组要发出，运算符将返回单个元组或空标记。
	- 运算符实现一个循环，在其子项上调用 Next 来检索它们的元组，然后处理它们。 这样，在父级上调用 Next 会在其子级上调用 Next。 作为响应，子节点将返回父节点必须处理的下一个元组。
- 迭代器模型允许流水线操作，其中 DBMS 可以在必须检索下一个元组之前通过尽可能多的运算符处理一个元组。 为查询计划中的给定元组执行的一系列任务称为管道。
- 一些运算符会阻塞，直到孩子发出所有元组。 此类运算符的示例包括连接、子查询和排序 (ORDER BY)。 这样的运营商被称为管道断路器。使用这种方法 (LIMIT) 可以轻松实现输出控制，因为一旦运算符拥有所需的所有元组，它就可以停止对其子运算符调用 Next。
- ![](pics/Pasted%20image%2020230502155933.png)

- 什么是火山模型，有啥优缺点？
	- 火山模型，又叫迭代器模型，它是数据库中一种数据处理模式。数据库对每个运算符都实现了 Next 操作，数据库执行一条 SQL 语句的时候，先将通过语法分析将其转化为一个抽象语法树，火山模型的话，会对每个节点都实现一个 Next 操作，处理这条语句的时候，在根节点上会递归调用每个子节点的 Next 函数，直到叶子节点，叶子节点将处理的一条数据返回给父节点进行处理。
	- 优点就是，每次从上往下只处理一个节点的数据，避免了处理大量数据的时候，需要存放在磁盘 IO 中，提高了查询处理的效率。
- 优化器有哪些？
	- 谓词下推、列裁剪、HashJoin

- 先是 **解析器** 将 SQL 语句解析成一棵抽象语法树 AST，然后 **绑定器** 会将这个 AST 绑定到数据库实体上，绑定之后生成一个查询计划树，再通过 **优化器** 得到最终的查询计划树，然后再通过执行引擎执行这条 SQL 语句，我实现的就是执行 SQL 语句的一些算子，
- 生成算子的步骤很简单，遍历查询计划树，将树上的 PlanNode 替换成对应的 Executor。算子的执行模型也大致分为三种：
1. Iterator Model，或 Pipeline Model，或火山模型。每个算子都有 `Init()` 和 `Next()` 两个方法。`Init()` 对算子进行初始化工作。`Next()` 则是向下层算子请求下一条数据。当 `Next()` 返回 false 时，则代表下层算子已经没有剩余数据，迭代结束。可以看到，火山模型一次调用请求一条数据，占用内存较小，但函数调用开销大，特别是虚函数调用造成 cache miss 等问题。
2. Materialization Model. 所有算子立即计算出所有结果并返回。和 Iterator Model 相反。这种模型的弊端显而易见，当数据量较大时，内存占用很高。但减少了函数调用的开销。比较适合查询数据量较小的 OLTP workloads。
3. Vectorization Model. 对上面两种模型的中和，一次调用返回一批数据。利于 SIMD 加速。目前比较先进的 OLAP 数据库都采用这种模型。


---
- 并发控制：并发控制方法是 DBMS 如何在运行时决定来自多个事务的操作的正确交错。有两种策略：
	- 1. 悲观：DBMS 假设事务会发生冲突，所以它不会让问题出现在第一时间。
	- 2.乐观：DBMS 假设事务之间的冲突是很少见的，所以它选择在事务提交后发生冲突时进行处理
- 可能的冲突：
	- 读写冲突（“不可重复读取”）：事务在多次读取同一对象时无法获得相同的值。
	- 写 - 读冲突（“脏读”）：一个事务在另一个事务提交其更改之前看到了另一个事务的写入效果。
	- 写 - 写冲突（“丢失更新”）：一个事务覆盖了另一个并发事务未提交的数据。

- 冲突可串行化：如果两个调度涉及相同事务的相同操作并且每对冲突操作在两个调度中以相同方式排序，则它们是冲突等价的。 如果调度 S 与某个串行调度冲突等效，则它是冲突可序列化的。

- 事务的锁管理器：DBMS 使用锁为可序列化的事务动态生成执行计划，而无需提前知道每个事务的读/写集。 当有多个读取器和写入器时，这些锁在并发访问期间保护数据库对象。 DBMS 包含一个集中的锁管理器，它决定事务是否可以获取锁。 它还提供了系统内部正在发生的事情的全局视图。
- 两种类型的锁：
	- 共享锁（S-LOCK）：允许多个事务同时读取同一个对象的共享锁。 如果一个事务持有共享锁，那么另一个事务也可以获得同一个共享锁。
	- 排他锁 (X-LOCK)：排他锁允许事务修改对象。 此锁可防止其他事务获取对象上的任何其他锁（S-LOCK 或 X-LOCK）。 一次只有一个事务可以持有排他锁。

- 锁管理器作用：事务必须向锁管理器请求锁（或升级）。 锁管理器根据其他事务当前持有的锁来授予或阻止请求。 事务在不再需要锁以释放对象时必须释放锁。 锁管理器使用有关哪些事务持有哪些锁以及哪些事务正在等待获取锁的信息更新其内部锁表。

- 2PL：两阶段锁定 (2PL) 是一种悲观并发控制协议，它使用锁来确定是否允许事务动态访问数据库中的对象。 协议不需要提前知道事务将执行的所有查询。
	- Phase #1 – Growing：在增长阶段，每个事务从 DBMS 的锁管理器请求它需要的锁。 锁管理器授予/拒绝这些锁请求。
	- Phase #2 – Shrinking：事务在释放第一个锁后立即进入收缩阶段。 在收缩阶段，事务只允许释放锁。 他们不允许获得新的。

- 死锁检测：DFS 发现环，取出 txn_id 最大的，将其状态设为 Abort，即终止事务；
- 死锁预防：
- 并发控制，什么是 2PL，锁管理器如何实现的？

- 3 种隔离级别：Repeatable Read、Read Committed、Read Uncommitted 是数据库中常见的三种事务隔离级别。它们分别指定了事务在读取数据时对于其他正在并发执行的事务所做的可见性规则。
	- 1. Read Uncommitted：最低的隔离级别。允许一个事务读取另一个事务未提交的数据，可能会导致脏读、不可重复读和幻读等问题。
	- 2. Read Committed：保证一个事务提交后才能被另一个事务读取，避免了脏读，但是还存在不可重复读和幻读等问题。
	- 3. Repeatable Read：保证在同一事务中多次读取同样的数据结果相同，避免了脏读和不可重复读，但是仍然存在幻读问题。

意向锁的作用：
- 数据库中的意向锁是一种特殊的锁，用于协调在表级别和行级别上使用共享锁和独占锁时的互斥关系。它们用于指示一个事务想要锁定某个表或表中一部分的意图，但尚未实际锁定任何东西。
- 这对于提高并发性能非常重要，因为多个事务可以共享相同的意向锁，而不会相互阻塞。例如，如果两个事务都希望在表的某个范围内插入新行，则可以共享意向插入锁，从而避免了彼此之间的阻塞。
- 意向锁还有助于减轻死锁问题，因为当事务需要在表或表的某个区域上获得独占锁时，它可以首先申请对应的意向锁。这样，在其他事务尝试申请与该意向锁冲突的锁时，就可以立即发现冲突，并进行适当的处理。

- 为了支持 **读未提交** 隔离级别，只在 Growing 阶段支持排他锁，而所有阶段都不支持共享锁，如果同时有多个事务尝试获取共享锁来访问同一行数据，且其中一个事务并不提交，那么其他事务就会被阻塞，无法继续执行。
- **可重复读** 隔离级别，Growing 支持任何的锁，收缩阶段不支持任何的锁，因为可重复读级别下，同一个事务多次读取的数据要保证一致，事务会在整个事务周期内持有读写锁，因此如果在收缩阶段获取锁，可能会导致其他事务无法访问数据，从而影响并发性能和系统吞吐量
- 在 **读已提交** 的隔离级别下，事务只能读取已经提交的数据，因此需要在读取数据时获取共享锁。由于收缩阶段是为了释放锁资源，所以只支持共享锁来避免死锁的发生。

---
DiskManager：作用和文件进行交互，实现了读和写 page 的功能

[缓存替换策略：LRU-K算法详解及其C++实现 CMU15-445 Project#1_AntiO2的博客-CSDN博客](https://blog.csdn.net/AntiO2/article/details/128439155)

分享类，不能做交流，