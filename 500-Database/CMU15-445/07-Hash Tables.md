## 1 Data Structures

一个数据库管理系统（DBMS）在系统内部的许多不同部分使用各种数据结构。一些示例包括：

1. **内部元数据（Internal Meta-Data）**：这是用于跟踪数据库和系统状态信息的数据。例如：页表（Page tables）、页目录（Page directories）。
2. **核心数据存储（Core Data Storage）**：用来存放数据库中的元祖。
3. **临时数据结构（Temporary Data Structures）**：DBMS 可以在处理查询时，动态构建数据结构，用来加快执行速度（例如，用于连接操作的哈希表）。
4. **表索引（Table Indices）**：辅助数据结构可以更加容易地查找特定的元组，以提高检索性能。

在实现 DBMS 的数据结构时，需要考虑以下两个主要的设计决策：

1. **数据组织（Data organization）**：我们需要确定内存如何布局，以及在数据结构内部存储需要哪些信息，以支持高效的访问。
   - 数据组织决策涉及到如何将数据存储在物理存储介质上，以确保快速的读取和写入操作。这包括选择适当的数据结构，确定数据的排列方式，以及是否使用索引等技术来加速数据访问。
2. **并发性（Concurrency）**：我们还需要考虑如何使多个线程能够访问数据结构而不引发问题。
   - 并发性决策涉及到如何处理多个并发读取和写入操作，以确保数据的一致性和完整性。这可能包括使用锁、事务管理、并发控制策略等技术来管理多线程访问数据的竞争条件。

## 2 Hash Table

**哈希表（Hash Table）** 实现了一个关联数组抽象数据类型，它将键映射到值。它提供了平均 O(1) 的操作复杂度（在最坏情况下为 O(n)），以及 O(n) 的存储复杂度。需要注意的是，即使平均操作复杂度是 O(1)，在数据库中，常数因子的优化也是需要考虑的重要因素。

> 以下来自 gpt：  
	哈希表之所以具有平均 O(1) 的操作复杂度，是因为它使用哈希函数将键映射到一个固定大小的数组（通常称为哈希表桶），然后通过该数组快速查找值。然而，在实际情况中，有一些因素可能影响哈希表的性能，包括：
>1. 哈希冲突（Hash Collisions）：当不同的键映射到相同的哈希桶时，就会发生哈希冲突。解决哈希冲突的方法包括链表法、开放寻址法和二次哈希等。选择适当的解决方案可以减少哈希冲突对性能的影响。
>2. 负载因子（Load Factor）：负载因子表示哈希表中已存储元素的比例。当负载因子过高时，哈希表可能需要重新调整大小（即重新哈希），以保持性能。因此，管理负载因子也是优化的一部分。
> 3. 哈希函数质量：选择良好的哈希函数对于分布键的均匀性很重要，这有助于减少冲突并提高性能。
> 4. 内存分配和数据结构细节：哈希表的实际实现细节，包括内存分配和桶的大小，也会影响性能。

哈希表的实现由两部分组成：

1. **哈希函数（Hash Function）**：哈希函数告诉我们如何将一个大的键空间映射到一个较小的域中。它用于计算数组桶或槽的索引。在选择哈希函数时，需要权衡快速执行和冲突率之间的关系。在极端情况下，有一个总是返回常数的哈希函数（非常快，但会导致所有键都冲突）。在另一个极端，有一个“完美”的哈希函数，不存在冲突，但计算速度极慢。理想的设计通常需要在两者之间取得平衡。
2. **哈希方案（Hashing Scheme）**：哈希方案告诉我们如何处理哈希后的键冲突。在这里，需要考虑在哈希发生冲突时分配大型哈希表以减少冲突和在冲突发生时执行额外指令之间的权衡。常见的处理冲突的方法包括链地址法（Chaining）、开放寻址法（Open Addressing）、二次哈希（Double Hashing）等。

## 3 Hash Functions

哈希函数（Hash Functions）接受任何键作为输入，并返回该键的整数表示（即“哈希”）。**哈希函数的输出是确定性的，即相同的键应该始终生成相同的哈希输出。**

DBMS 不需要使用加密安全的哈希函数（例如 SHA-256），因为我们不需要担心保护键的内容。这些哈希函数主要用于 DBMS 的内部，并且不会泄漏到系统外部。通常，我们只关心哈希函数的速度和冲突率。

目前，Facebook 的 XXHash3 被认为是最先进的哈希函数，它在速度和性能方面表现出色。

![](pics/Pasted%20image%2020230904161055.png)

## 4 Static Hashing Schemes

静态哈希方案（Static Hashing Schemes）中哈希表的大小是固定。这意味着如果 DBMS 在哈希表中的存储空间用完，那么它必须从头开始重新构建一个更大的哈希表，一般是 2 被扩容，扩容是比较耗费时间的。

为了减少比较次数，重要的是要避免键的哈希冲突。一般会将哈希表的槽位数设置为预期元素数量的两倍。以下假设在实际应用中通常不成立：
1. 已提前知道元素的数量。
2. 键是唯一的。
3. 存在一个完美的哈希函数。

因此需要考虑合适哈希函数和哈希方案。
### 4.1 Linear Probe Hashing

线性探测哈希（Linear Probe Hashing）这是最基本的哈希方案，通常也是最快的。它使用一个循环缓冲区的数组槽位。哈希函数将键映射到槽位。

![](pics/Pasted%20image%2020230904162123.png)

当发生冲突时，线性搜索相邻的槽位，直到找到一个空的槽位。对于查找，可以检查键哈希到的槽位，并线性搜索直到找到所需的条目。如果我们到达一个空槽位或遍历了哈希表中的每个槽位，那么该键不在表中。需要注意的是，这意味着我们必须在槽位中存储键和值，以便可以检查条目是否是所需的。

![](pics/Pasted%20image%2020230904162335.png)

删除操作稍微复杂点，因为删除一个之后，这个位置是空的，可能会影响后续元素的查找，比如说将上面的 C 删除，假设 D 最开始映射的位置也是 C，因为 D 之前已经有 C 了，就将 D 放到 C 的下一个位置：

![](pics/Pasted%20image%2020230904162806.png)

此时我们再查找 D 的话，发现计算位置上是空的，会以为哈希表中没有 D，但是实际上 D 是在下一个位置。

![](pics/Pasted%20image%2020230904162824.png)

为了解决上面的问题，一般有两种方案：
1. 移动：删除元素之后，将相邻的数据移动到现在的空槽位。实际中很少这样做。

![](pics/Pasted%20image%2020230904163051.png)

2. 墓碑（tombstones）：删除的条目并不实际删除，而是做一个墓碑标记，这样就可以告诉后面的查询可以继续找下一个位置。标记为墓碑的位置在后续过程中还可以放入新的条目。

![](pics/Pasted%20image%2020230904163230.png)

#### Non-unique Keys

对于非唯一键（Non-unique Keys）的情况，其中同一个键可能与多个不同的值或元组相关联，有两种常见的处理方法：

1. **分离链表（Seperate Linked List）**：可以将一个指针存储在哈希表的槽位中，该指针指向一个单独的存储区域，其中包含所有与该键相关的值的链表。这种方法将键与值分开存储，允许一个键关联多个值。
2. **冗余键（Redundant Keys）**：更常见的方法是在哈希表中多次存储相同的键，每个键关联一个值。即使采用线性探测哈希等开放寻址法，仍然可以正常工作。当进行查找时，需要查找所有与该键匹配的槽位，直到找到所需的值。

![](pics/Pasted%20image%2020230904163722.png)

这两种方法各有优点和缺点：
- **分离链表** 的优点是它允许在不重复存储键的情况下关联多个值，从而节省了内存。然而，它需要额外的内存来存储链表，并可能需要更多的指针操作。
- **冗余键** 的优点是实现相对简单，无需额外的指针和链表操作。但它会占用更多的内存，因为键被重复存储，并且可能导致哈希表填充得更快。

### 4.2 Robin Hood Hashing

Robin Hood Hashing 是线性探测哈希的一种扩展，旨在减少每个键距离其最佳位置（即它们最初哈希到的槽位）在哈希表中的最大距离。这个策略从“富有”的键中夺取槽位并分配给“贫穷”的键。

在这种变体中，每个条目还记录了它们距离最佳位置的**距离**。然后，在每次插入操作中，如果要插入的键在当前槽位的最佳位置上距离比当前条目的距离更远，我们将替换当前条目，并继续尝试将旧条目插入表的更远位置。

这种方法的目标是尽量减小键的移动距离，从而提高哈希表的性能。通过将键从一个位置移到另一个位置，以减小键的距离，可以减少线性探测中的聚集问题（clustering）和减少查找所需的步骤。

这种方法的实现可能会更复杂，因为它需要记录每个条目的距离，并在插入时执行复杂的位置交换。然而，在某些情况下，这种策略可以提高哈希表的性能，特别是在面临高冲突率的情况下。

下面是课程上关于这个哈希的演示：

假设已经插入 B 和 A 了，它们都在自己的理想位置，方括号表示这个条目的当前位置与理想位置之间的差值。

![](pics/Pasted%20image%2020230904164335.png)

假设 C 计算得到的 hash 值和 A 是一样的，即 C 的理想位置也是 2，而 A[0] == C[0] 它们的距离都是零，不存在谁距离更大，所以将 C 放到下一个位置上：

![](pics/Pasted%20image%2020230904164604.png)

假设现在继续插入 D，它的 hash 值是 3，即 C 的位置，由于 C[1] > D[0]，D 不能放到 C 的位置上，否则 C 需要放在更远的位置上了：

![](pics/Pasted%20image%2020230904164734.png)

现在继续插入 E，假设它的 hash 值为 2，即 A 的位置。由于 A[0] == E[0]，所以 E 不能抢占 A 的位置，而 E[1] == C[1]，E 也不能抢占 C 的位置。但是 E[2] > D[1]，E 与自己的理想位置更远，所以 E 抢占了 D 的位置，将 D 放在更加靠后的位置上：

![](pics/Pasted%20image%2020230904165015.png)

## 4.3 Cuckoo Hashing

这种方法不同于使用单一哈希表，它维护了多个具有不同哈希函数的哈希表。这些哈希函数是相同算法（例如，XXHash、CityHash），它们通过使用不同的种子值为相同的键生成不同的哈希值。

在插入操作时，会检查每个哈希表，并选择其中一个具有空闲槽位（如果有多个哈希表都有空闲槽位，可以比较负载因子等条件，或更常见的是随机选择一个哈希表）。如果没有哈希表有空闲槽位，那么通常会选择其中一个（通常是随机选择）并将旧条目驱逐出去。然后，将旧条目重新哈希到不同的哈希表中。在罕见的情况下，可能会出现循环。如果发生这种情况，可以重新构建所有的哈希表，使用新的哈希函数种子（较不常见），或者使用更大的表格重新构建哈希表（更常见）。

这种技术被称为**杜鹃哈希（Cuckoo Hashing）**，它保证了 O(1) 的查找和删除操作，但插入操作可能会更昂贵。它的主要优点是能够提供快速的查找和删除性能，但在处理插入冲突时需要进行一些复杂的重新哈希操作。

开源实现：[efficient/libcuckoo: A high-performance, concurrent hash table (github.com)](https://github.com/efficient/libcuckoo)  
假设现在有 2 个哈希表，每个哈希表各有一个哈希函数，现在需要插入 A，分别计算两个哈希表中的位置，可以发现 1 号哈希表插入的位置是 1，2 号哈希表插入的位置是 3，并且都没有冲突，所以可以随机选一个插入，假设这里选择 1 号哈希表：

![](pics/Pasted%20image%2020230904170236.png)  
![](pics/Pasted%20image%2020230904170255.png)

现在继续插入 B，分别计算得到在 1 号哈希表的位置 1，在 2 号哈希表的位置 0，因为 1 号哈希表中发生冲突，所以选择插入到 2 号哈希表中：

![](pics/Pasted%20image%2020230904170354.png)  
![](pics/Pasted%20image%2020230904170404.png)

继续插入 C，发现插入的位置都冲突了，这个时候选择剔除一个条目，假设剔除了 B：

![](pics/Pasted%20image%2020230904170610.png)  
![](pics/Pasted%20image%2020230904170624.png)

这个时候需要将 B 插入到 1 号哈希表中（因为是从 2 号哈希表剔除出来的，不能再放回去，不然就出现循环情况了），这里也发现是冲突的，所以将 A 剔除：

![](pics/Pasted%20image%2020230904170748.png)  
![](pics/Pasted%20image%2020230904170756.png)

现在需要将 A 插入到 2 号哈希表中，此时没有冲突了。

![](pics/Pasted%20image%2020230904170834.png)

如果上面的 A 插入的 2 号哈希表的位置是 C 所在位置的话，就产生了循环，这个时候考虑重新使用哈希函数，或者重新构建哈希表等。

### Observation

前面的哈希表要求 DBMS 知道要存储的元素个数，否则如果需要增加或减少表格的大小，就必须重新构建哈希表。下面介绍的动态哈希表将会按需进行分配大小。

## 5 Dynamic Hashing Schemes

静态哈希方案需要在开始时确定哈希表的大小，因此需要提前知道要存储的元素数量。如果元素数量超出了初始大小，就需要重新构建整个哈希表，这可能会导致性能下降和额外的开销。

动态哈希方案具有自动调整大小的能力，可以在运行时根据需要自动扩展或缩小哈希表的大小，而不需要事先知道元素数量。这种动态调整大小的能力使得动态哈希表更加适用于处理不确定的数据量和动态变化的情况。不同的动态哈希方案可以通过不同的策略来调整大小，以优化读取或写入操作的性能，以满足特定应用的需求。

### 5.1 Chained Hashing

开链哈希（Chained Hashing）：这是最常用的动态哈希方案。DBMS 对于哈希表中的每个槽都维护一个桶，这些桶通过链表串联起来。哈希在相同槽的键，会插入的桶当中。

![](pics/Pasted%20image%2020230904171922.png)

这种方法比较简单，但是当冲突比较多的时候，会退化成链表，查询时间复杂度降为 O(n)。

### 5.2 Extendible Hashing

可拓展哈希（Extendible Hashing）是一种改进的开链哈希（Chained Hashing），它采用了分裂桶而不是让链表无限增长的方式来处理哈希冲突。这种方法允许哈希表中的多个槽位指向相同的桶链。

以下是这种改进方法的核心思想：
1. **全局和局部深度位计数**：DBMS 维护全局深度和局部深度位计数，这些位计数用于确定在槽位数组中查找桶所需的位数。
2. **分裂桶**：当一个桶已满时，DBMS 会分裂该桶并重新排列其中的元素。如果分裂桶的局部深度小于全局深度，那么新桶只会被添加到现有的槽位数组中。否则，DBMS 会将槽位数组的大小翻倍，以容纳新的桶，并增加全局深度计数器。

通过分裂桶并增加全局深度，DBMS 增加了在哈希表中查找条目所需的位数。这意味着 DBMS 只需要在分裂链的桶中移动数据，而所有其他桶都保持不变。

这种方法的优点是它允许哈希表有效地处理哈希冲突，并在需要时动态调整哈希表的大小。它通过分裂桶并增加位数来避免链表无限增长，从而提高了性能和效率。

假设初始情况下全局深度为 2，局部深度和数据如下，第一个桶局部深度为 1，所以只比较第一位，剩下两个桶局部深度为 2，要比较两位。

![](pics/Pasted%20image%2020230904173346.png)

当查询 A 的时候，假设 `hash(A) = 01110...`，全局深度是 2，所以比较前两位，找到 0 1 对应的桶，也就是第一个桶，然后从里面在找到 A。

![](pics/Pasted%20image%2020230904173609.png)

现在插入 B，假设 `hash(B) = 10111...`，全局深度为 2，找到 1 0 对应的桶，发现是第 2 个桶，桶还有空间，将 B 插入进去。

![](pics/Pasted%20image%2020230904173557.png)

现在继续插入 C，假设 `hash(C) = 10100...`，同样的也是插入到第 2 个桶中，但是此时发现桶已经满了，无法继续插入。

![](pics/Pasted%20image%2020230904173754.png)

这个时候需要直接全局深度，global = 3，同时第 2 个桶分裂成 2 个局部深度为 3 的桶，这 2 个新桶需要将原来的元素重新找到对应的位置放入（比较前 3 位），最后对应关系如下：

![](pics/Pasted%20image%2020230904174013.png)

此时发现第 3 个桶也就是 101 有空余位置，将 C 插入进去：

![](pics/Pasted%20image%2020230904174151.png)

### 5.3 Linear Hashing

该方案不会在桶溢出时立即分裂桶，而是维护一个分裂指针（split pointer）来跟踪下一个要分裂的桶。 无论这个指针是否指向溢出的桶，DBMS 总是会分裂。 溢出标准由具体的实现决定。  
• 当任何桶溢出时，通过添加新的槽条目在指针位置拆分桶，并创建新的哈希函数。  
• 如果散列函数映射到先前已由指针指向的槽，则应用新的散列函数。  
• 当指针到达最后一个槽时，删除原来的哈希函数并用新的哈希函数替换它。

假设现在哈希表的情况如下：分裂指针指向槽位 0，现在想获取 6，哈希函数 hash1 是对 n 简单取模，所以计算得到 2，从槽位 2 中查询，发现有 6 这个键。

![](pics/Pasted%20image%2020230904175714.png)

现在想插入 17，根据 hash1 计算结果为 1，但是此时槽位 1 对应的桶已经满了，需要分裂，分裂指针指向的是槽位 0，所以分裂这个桶。

![](pics/Pasted%20image%2020230904175858.png)

用新的哈希函数 hash2 计算桶 0 中的所有元素，将他们放到对应的位置上：

![](pics/Pasted%20image%2020230904180050.png)

此时如果查询 20，先用 hash1 计算发现为 0，但是这里面没有 20，因为槽位 0 的桶已经分裂过一次了，所以这时候用新的 hash2 计算一下，此时找到了 20， 并将分裂指针往后移动一位。

![](pics/Pasted%20image%2020230904180252.png)  
![](pics/Pasted%20image%2020230904180423.png)

分裂指针会一直移动，直到所有的桶都分裂过一次，这个时候会将旧的哈希函数删除，用新的哈希函数，重新上面的步骤。